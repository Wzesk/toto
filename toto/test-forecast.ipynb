{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2c0ae11",
   "metadata": {},
   "source": [
    "why use toto: https://huggingface.co/spaces/Salesforce/GIFT-Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21b7469f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/toto/lib/python3.13/site-packages/gluonts/json.py:102: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from data.util.dataset import MaskedTimeseries\n",
    "from inference.forecaster import TotoForecaster\n",
    "from model.toto import Toto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a0bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "toto = Toto.from_pretrained('Datadog/Toto-Open-Base-1.0')\n",
    "toto.to('cuda')  # Move to GPU\n",
    "\n",
    "# Optionally compile the model for faster inference\n",
    "toto.compile()  # Uses Torch's JIT compilation for better performance\n",
    "\n",
    "forecaster = TotoForecaster(toto.model)\n",
    "\n",
    "# Prepare your input time series (channels, time_steps)\n",
    "input_series = torch.randn(7, 4096).to('cuda')  # Example with 7 variables and 4096 timesteps\n",
    "\n",
    "# Prepare timestamp information (optional, but expected by API; not used by the current model release)\n",
    "timestamp_seconds = torch.zeros(7, 4096).to('cuda')\n",
    "time_interval_seconds = torch.full((7,), 60*15).to('cuda')  # 15-minute intervals\n",
    "\n",
    "# Create a MaskedTimeseries object\n",
    "inputs = MaskedTimeseries(\n",
    "    series=input_series,\n",
    "    padding_mask=torch.full_like(input_series, True, dtype=torch.bool),\n",
    "    id_mask=torch.zeros_like(input_series),\n",
    "    timestamp_seconds=timestamp_seconds,\n",
    "    time_interval_seconds=time_interval_seconds,\n",
    ")\n",
    "\n",
    "# Generate forecasts for the next 336 timesteps\n",
    "forecast = forecaster.forecast(\n",
    "    inputs,\n",
    "    prediction_length=336,\n",
    "    num_samples=256,  # Number of samples for probabilistic forecasting\n",
    "    samples_per_batch=256,  # Control memory usage during inference\n",
    ")\n",
    "\n",
    "# Access results\n",
    "mean_prediction = forecast.mean  # Point forecasts\n",
    "prediction_samples = forecast.samples  # Probabilistic samples\n",
    "lower_quantile = forecast.quantile(0.1)  # 10th percentile for lower confidence bound\n",
    "upper_quantile = forecast.quantile(0.9)  # 90th percentile for upper confidence bound"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
